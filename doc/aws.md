# aws.md

## VPC

### VPCエンドポイント

- VPCとAWSサービス巻でプライベート接続(VPC - VPC ではない)
- リージョンを跨いだ接続は提供していない

## RDS

### マイナーバージョンの自動アップグレード

- 8.5.3を8.5.4に自動にあげる。 8.5を8.6にする訳ではない
- クラスター、インスタンス、どちらにも設定できる
- クラスターの有効を無効に切り替えた場合、インスタンスも無効になった

### 最小インスタンス

- t4g.micro
- serveles modelは自動スケーリングしちゃうので少し高価

## Redshift

### 暗号化

- 暗号化されていない既存のRedshiftクラスタを暗号化する場合
  1. 新しい暗号化されたクラスタを作成
  1. データをそのクラスタにマイグレート

### マニフェストファイル

- Redshiftにロードするデータファイルを定義したjson
- このファイルを使用するとRedshiftは1つのCOPYコマンドを使用して複数のファイルを並列で取り込むことができる

### コンカレンシースケーリング

- 複数のクエリが一度に送信された場合、クラスタキャパシティを自動的に追加。

### エラスティックリサイズ

- ノードタイプを変更せずにノードを追加し、パフォーマンスを上げることができる(手動操作)
- `クラシックリサイズ` は ノード追加かつノードタイプも変更できるがダウンタイムが発生する

### Redshift Serverless

- 使用量に対してのみ料金が発生する。テスト環境とかに良いかも
- データ共有を使用すると、追加コストを発生させることなく、RedshiftクラスターとRedshift Serverlessエンドポイント間でライブデータを共有できる

### マテリアライズドビュー

- S3等のデータ読み込みをビューで作成しておくと効率的
- AUTO REFRESH YESをビュー作成時に登録しておくと、自動更新する
  - Refreshは基本的に増分更新
  - 増分更新できない場合はフル更新になる

### Redshift Spectrum

- S3を始めとした各種ストレージサービスに対して、Redshiftによるクエリを実現するサービスです。

- S3 Glacier Deep Archiveのデータにアクセス、また、Deep Archiveに対してクエリを発行することはできない
- S3 Glacier Deep Archiveに直接データのアンロードもできない

### Diststyle

|        |                                                                                                              |
| ------ | ------------------------------------------------------------------------------------------------------------ |
| AUTO   | (デフォルト)分散スタイルを小さなテーブルに割り当て、その後テーブルが大きくなると、テーブルを EVEN 分散に変更 |
| EVEN   | ラウンドロビン分散方式で、テーブルデータをクラスター内のノード全体に均等に分散                               |
| KEY    | データは、DISTKEY 列の値で分散                                                                               |
| ALL    | テーブル全体のコピーがすべてのノードに分散                                                                   |
| UNLOAD | クエリの結果をS3にエクスポート、出力形式はテキスト、CSV、Parquet、JSON等                                     |

### SQLのコマンド

|        |                                        |
| ------ | -------------------------------------- |
| COPY   | データファイルをテーブルにコピー       |
| INSERT | 行の追加(大量データには向かない)       |
| VACUUM | 行を再ソートしてスペース(容量)を再利用 |

## EBS

- AZ内に複製される（AZの障害に弱い）

## EFS

- リージョン内の複数AZに格納される

## Lambda

- タイムアウトは15分
- 1つのアカウントに対し、同一リージョンで最大1000個同時に動作
-

## S3

### ストレージクラス

IAはInfrequent-Access(低頻度アクセス）のこと

|                            |                                                                            |
| -------------------------- | -------------------------------------------------------------------------- |
| Standard                   | 標準                                                                       |
| Intelligent-Tiering        | アクセス頻度が分からないオブジェクト向け。自動で階層移動してくれる         |
| Standard IA                | アクセス頻度が低いデータ向け。データ取り出しに課金される                   |
| One Zone IA                | 他クラスが3つ以上のAZにデータを保存するのに対し、1つのAZのみにデータを保存 |
| Glacier Instant Retrieval  | 即取り出し可能                                                             |
| Glacier Flexible Retrieval | データ取り出しに数分から12時間程度の遅延あり                               |
| Glacier Deep Archive       | 最低料金 データ取り出しに12時間から48時間かかる                            |
| Intelligent Tiering        | アクセス頻度に基づいて費用対効果の高いアクセス階層に自動で変化する         |
| Outposts                   | オンプレミスで保存したいデータ向け                                         |

### S3 Select, Glacier Select

- S3, Glacierに対してSQLで情報取得が可能
- Glacier Selectは 情報取得に何時間もかかる訳ではない。データ量とリクエスト数で料金が変わる

## SQS

- SQSからキューが削除されるタイミング
  - SQSに対してDeleteMessage APIを呼び出す
  - maxReceiveCountが最大受信数に達した
  - キューがパージされた

## Kinesis Data Streams

- 高度なカスタマイズ＆よりリアルタイムなデータストリーミングサービス
- ProvisionedThroughputExceededExceptionが発生した場合

  - データストリームの容量クォータがプロビジョンされた量を超えていることが原因
    - アプリケーション側の実装を修正し、ストリームからのデータ読み取りを再試行させる
    - ストリーム内のシャード数を付与足、データ呼び出しに十分な容量を確保する

- シャード毎にLambda関数の同時インスタンスが1つ
  - シャードが3つある場合は3つの関数を同時に使用可能

### Error

- IteratorAgeが高い
  - Kinesisデータストリームから読み取られる最後のレコードが最新のものからかけ離れている
    - 拡張ファンアウトのコンシューマーにLamdda関数を登録する
    - シャード数を増やす
      - シャード毎にLambda関数の同時インスタンスが1つだけ（シャードが3つある場合は3つの関数を同時に使用可能）

### 拡張ファンアウト

- コンシューマーとシャード間に論理的な2 MB/秒スループットパイプを提供
- 以下のケースで利用が推奨
  - 普通に複数のコンシューマーを設計すると、Kinesis Data Streamsの性能制限を超えてしまう場合
  - 200ms以下のデータ提供速度を求める場合

## Kinesis Data Firehose

- できることは大体Data Streamsと一緒
- 簡単なデータ変換＆よりシンプルなデータストリーミングサービス
- データ変換Lambda関数を使用してデータ変換が可能

## Elastic Kubernetes Service (Amazon EKS)

- Kubernetesのマネージドサービス、 コンテナオーケストレーター
- コンテナはポッドで実行される、 ポッドはノード上で実行される
  - ノードはEC2 or Fargate
  - エフェメラルボリュームはポッドと同じライフサイクル

## Glue

- ジョブ実行モニタリングセクションを使用すると、このシナリオに適したDPU容量を判断できます

### DataFrame

- Sparkが提供する分散データフレーム
- テーブルのような構造でデータを保持し、SQLライクな操作を行うことができる。DataFrameは、Python、Scala、Java、Rなどの多くの言語で使用可能

### DynamicFrame

- AWS Glueが提供するデータフレーム。DynamicFrameは、DataFrameに比べて、より柔軟なスキーマ設計が可能です。DynamicFrameは、PythonまたはScalaで使用可能
- テーブルのような構造ではなく、1つ以上のダイナミックなスキーマを持つコレクション。データを変換するための操作をより簡単に実行することができる。

### ジョブブックマーク

- 以前に処理されたデータを追跡する際に使用

### ジョブメトリック

- 有効にするとジョブの実行に関するインサイトを提供する

## Macie

- S3内の機密情報の検出
  (GlueはS3以外もいけるが、MacieはS3特化）

## Lake Formation

- データベース、テーブル、列、行、セルのレベルでセキュリティを実装

## AppFlow

- ソースとターゲットの間でデータを転送する
  ソースにはTeams, Slack等が選択可能
- オーバーヘッドを最小限に抑えながら、Amazon Redshiftに継続的にデータを送信できます。

## SageMaker

### Feature Store

- 機械学習モデルの機能を作成、保存、共有することが

### 機械学習リネージトラッキング

- 機械学習ワークフローのステップに関する情報を作成し、保存できる
- モデルのガバナンスと監査基準を確立できる
- 機械学習の意思決定の実行に使用されるデータが正確、完全、かつ信頼できるものであることを確認できます。

### Data Wrangler

- EDAを実行し、機械学習で使用するデータを準備できる
  - 探索的データ分析（EDA）とは、データサイエンティストがデータセットを分析・調査して、その主な特徴をまとめる際に用いるもの

### SageMaker Processing

- データ処理ワークロード、データ検証、モデル評価、モデル解釈などの操作を実行するために使用できるマネージドサービス

## Athena

- S3からSQLクエリでデータ抽出が可能
- S3 Selectよりも高機能 かつ Athenaは分析目的で使用される S3 Selectはデータ抽出目的な感じ
- Glue Data Catalogを使うと、スキーマ定義をある程度自動でやってくれる
- リアルタイム処理はちょっと苦手。

### 料金

- スキャンするデータ量に基づくので、データの圧縮、分割が効果的

## EMR

- Apache HadoopやApache Sparkなどのオープンソースツールを利用した、ビッグデータの分析が可能なAWSサービス

### Hadoop

- 大量のデータを手軽に複数のマシンに分散して処理できるオープンソースのプラットフォーム
- Hadoop Distributed File System (HDFS) と呼ばれるネイティブファイルシステムがあ

#### YARN

- HDFSに保存されたデータから分散処理をする際に、どの計算リソースにどれくらいのCPUメモリを割り振るかを管理するもの

#### MapReduce

- MapとReduceがセットになっており、Map並列処理をして、Reduceで統合する、という流れを繰り返しす
- 例えばSUMを計算する場合は複数のMapそれぞれで和の計算を並列で行い、Reduceでそれぞれの結果を統合する
- 実行時に遅くなることもあり最近はあまり使われていないとか(https://qiita.com/tetsuro731/items/64abce51021c904bb7ab#mapreduce)

#### Hive

- クエリエンジン
- MapReduceの演算結果をSQLライクに取り出せるように開発された言語

#### Presto

- クエリエンジン
- PrestoではYARNのようなリソースマネージャを使わず、中間データもディスクに書き出さず全てメモリ上で処理
  - Hiveよりも高速なこともあれば、遅くなることもあるとか
- S3, RDBMS, OpenSearchなど、さまざまなソースにクエリを投げられる

#### HBase

- NoSql
- Hadoop データをリアルタイムで保存および処理する
  - Hive は Hadoop または Spark に SQL 機能を提供
- HBase はリアルタイムのクエリやビッグデータに使われる
  - Hive はリアルタイムのクエリには向いていない
- Hive はデータの分析クエリに最適で、HBase は主に非構造化 Hadoop データをレイクとして保存または処理するために使用される。

#### Sqoop

- RDBMS などの構造化データ ソースからデータをインポートするために使用される

#### Apatch ORC / Apatch Parquet

- 列指向型のファイルフォーマット

### Spark

- 多数のマシンにまたがって並列でコードを実行するための、洗練された分散処理フレームワーク

## DMS(Database Migration Service)

- DBのAWS移行

## SCT

- 異なるデータベースの移行をサポート

## Data Sync

- AWSへの安全なデータ移行

## Snowball

- 大規模なデータ移行
  - 最初のデータ移行はSnowballを使用して、その後の差分データ移行はData Syncを使うという手もある

## QuickSight

- データの見えるか
- Athena, Redshift, OpenSearchなどからデータを取得できる

### SPICE

- インメモリのエンジン
- ここにデータをロードすると早く表示できる
- SPICEは元になるデータソースのパーミッションが必要。例えばAWS Glue Data Catalog ではなく、S3のパーミッション。
